	unsigned int i, j;

	for (i = 0; i < N; i++) {
		x[i] += z[i];

		__m256 vec_u1 = _mm256_set1_ps(u1[i]);
		__m256 vec_u2 = _mm256_set1_ps(u2[i]);

		__m256 vec_beta_y = _mm256_set1_ps(beta * y[i]);
	
		for (j = 0; j < N; j+=8) {
			// A[i][j] += temp_u1 * v1[j] + temp_u2 * v2[j];
			__m256 vec_v1 = _mm256_load_ps(&v1[j]); // v1
			__m256 vec_v2 = _mm256_load_ps(&v2[j]); // v2

			__m256 vec_A = _mm256_load_ps(&A[i][j]); // A

			__m256 temp_uvA = _mm256_fmadd_ps(vec_u1, vec_v1, vec_A); // u1 * v1[j] + A[i][j]
			__m256 temp_uvAuv = _mm256_fmadd_ps(vec_u2, vec_v2, temp_uvA); //  u2 * v2[j] + temp_uvA

			_mm256_storeu_ps(&A[i][j], temp_uvAuv);

			// x[j] += A[i][j] * temp_beta_y;
			__m256 vec_x = _mm256_load_ps(&x[j]); // x

			__m256 temp_xAbetay = _mm256_fmadd_ps(temp_uvAuv, vec_beta_y, vec_x);  // A[i][j] * temp_beta_y + x[j]

			_mm256_store_ps(&x[j], temp_xAbetay);
		}
	}


	for (i = 0; i < N; i++) {

		__m256 vec_temp_w = _mm256_setzero_ps();

		__m256 vec_alpha = _mm256_set1_ps(alpha); // alpha

		for (j = 0; j < N; j+=8) {
			// temp_w += alpha * A[i][j] * x[j];
			__m256 vec_A = _mm256_load_ps(&A[i][j]); // A
			__m256 vec_x = _mm256_load_ps(&x[j]); // x

			__m256 vec_Ax = _mm256_mul_ps(vec_A, vec_x);// A[i][j] * x[j]

			vec_temp_w = _mm256_fmadd_ps(vec_alpha, vec_Ax, vec_temp_w); //  alpha * Ax + temp_w
		}

		//w[i] = temp_w;
		__m128 low = _mm256_extractf128_ps(vec_temp_w, 0); // low temp_w
		__m128 high = _mm256_extractf128_ps(vec_temp_w, 1); // high temp_w

		__m128 sum_lh = _mm_add_ps(low, high); // low + high

		sum_lh = _mm_hadd_ps(sum_lh, sum_lh); // (a0 + a1 , a2 + a3 , b0 + b1 , b2 + b3)
		sum_lh = _mm_hadd_ps(sum_lh, sum_lh); // (a0 + a1 + a2 + a3 , ...)

		w[i] = _mm_cvtss_f32(sum_lh); 
	}